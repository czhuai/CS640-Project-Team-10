human_text,human_text_len
"Forecasting the developing trend of COVID-19 has become a hot topic nowadays. However, two problem exits during training the models on the time series: At the early stage of an outbreak, the limited data are not enough to train a capable model. The outbreak in different regions may have different developing patterns, therefore a single model can’t simulate the pandemic spread in all regions well. Our project aims at providing solution to these problems. Using the time series forecasting models, we propose an approach to predict the trend of an outbreak using data from outbreak in other regions, develop an algorithm for grouping regions sharing similar developing pattern of a pandemic. Our experiments show that our proposed methods can effectively handle those challenges and give decent prediction results. In addition, we build a web application backed by our novel prediction algorithms. The web UI features interactive charts and maps, enabling users to have a clear picture of the ongoing situation of the pandemic.",163
"Pandemics such as Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) or coronavirus disease 2019 (COVID-19) have inserted dramatic influence on people’s health and their normal life globally. World health organization (WHO) declared on 11th March, 2020, the outbreak of COVID-19 as a pandemic. COVID-19 can cause severe respiratory problems and chronic diseases like cardiovascular disease or diabetes. In addition, COVID-19 can spread rapidly among people and symptoms of infected people have a relatively long incubation period before they are noticeable. Even worse, the virus has recently evolved into several variants recently which are more infectious and may resist the effects of current vaccines. The severe illness caused by COVID-19 and its strong infectiousness make it necessary to contain the spread of the virus as soon as possible.",127
"Therefore, this work is motivated to model the spread of COVID-19, which can help governments to manage public policies and arrange medical resources in order to better contain the coronavirus. More specifically, our project implements time series (TS) prediction of daily infected cases. Time series forecasting has been widely studied, which aims at making scientific predictions based on historical time stamped data. Several works have also been conducted on the application to the pandemic forecasting. Among those works, the recurrent neural network (RNN) architecture as a deep-learning model is widely adopted, especially long short-term memory (LSTM). However, those works on time series prediction are faced with two critical challenges: (1) At the early stage of a regional outbreak, there may not be enough historical data to train a capable deep learning model. (2) The outbreak in different regions may have different patterns of development, therefore it may be difficult for a single prediction model to learn and simulate the pandemic spread in all regions.",164
"Therefore, to fill the gaps, our work thus focuses on the early time series prediction of regional outbreaks. This task can be formulated as zero-shot or few-shot time series prediction (discussed in Sec. 2.1). Zero-shot or few-shot stands for the scarcity of available training data. To mitigate the shortage of data, we employ transfer learning. Transfer learning aims to extract the knowledge from one or more source tasks and applies the knowledge to a target task. In our case, we take the leverage of the relatively sufficient data from regions where the pandemic appears earlier. We also propose a grouping algorithm to assign regions of similar pandemic patterns into groups and train a separate model for each group. Additionally, in order to demonstrate our results, we design and implement a web user interface backed by our prediction models.",138
"The aims at providing solution of lack of data problem in the early stage forecasting and an approach to group the regions where the outbreak sharing similar developing patterns. During the project development, the following objectives were focused on:",39
"Among the three objectives, objectives 1 and 2 are the most critical and most innovative parts of our project, which are in fact the solution of questions we’d like to answer in this project. The objective 1 requires the development of algorithm that can evaluate the similarity of pandemic developing trend between different regions. And the objective 2 is based on the assumption that similarity exists between pattern in different regions, which can be proved by the successful achievement of objective 1.",82
"As several pandemics and seasonal influences have caused egregious loss and a staggering number of deaths, a huge number of time series forecasting projects has been conducted to estimate the casualties of epidemics. In this session we will go through some existing projects using different time series forecasting models.",49
"Wang et al. proposed an improved long short-term memory model (LSTM) deep learning method for time series forecasting for the epidemic trends of COVID-19. While the existing LSTM models trained with the total number of reported cases did provide an accurate short-term prediction, these models were not able to provide a long[1]term prediction curve, and they could only predict the rising trend. Therefore, instead of using the total number of cases like the previous research, the number of daily reported cases was used in this project to obtain the long-term prediction curve and predicting the declining trend and the end of epidemic. The data used was the country based daily reported cases between January 22, 2020, and July 7, 2020, collected from John Hopkins university",126
"The learning process of LSTM was improved by adopting a rolling update mechanism. The rolling update mechanism means the training samples are updated using the current prediction result. In the improved learning process, the collected real-time data was put into model, generating the prediction results of daily confirmed cases of the next day. This prediction result was added into the training data and generated the prediction results of daily confirmed cases of day after the next day. This iterative process generated the long-term prediction curve of the daily confirmed cases of COVID-19. According to their paper, the improved LSTM method provided a forecasting result of daily confirmed cases consistent with the real data and an accurate trend of epidemic.",119
"Lai applied three models to monitor the dynamic of SARS: an autoregressive model with order 1, a random walk model, and a combined model of growth curve fitting and autoregressive moving average. The data used was the newly reported SARS cases in mainland China from April 21, 2003, to May 31, 2003, collected from the official reports of the Ministry of Health of China.",64
"The autoregressive made a wrong assumption that the number of new daily reported cases is stationary, resulting in a higher prediction result compared to the actual values. The random walk model trained with the log transformed daily report cases provided a well model of the dynamic of daily reported cases and an accurate short-term prediction of the number of daily reported cases. The growth curve model provides an estimation function for the cumulative number of SARS cases, while the variability exists.",81
"Zhang et al. compared 4 time series models for modeling and predicting the dynamics of epidemic. The models compared are regression model, exponential smoothing model, autoregressive integrated moving average (ARIMA) model, and the support vector machine (SVM) model. The incidence time series of 9 epidemics from 2005 to 2012 collected from Chinese Center for Disease Prevention and Control (CDC) was used in the research.",64
"According to the paper, the SVM model generally outperformed 3 other models due to its ability to handle non-linear relationship and tolerance of complexity. The ARIMA model was able to capture the linear trend of the diseases effectively, however, it could not provide a satisfactory performance on diseases affected by multiple factors, and non-linear relationships existed in some diseases. The regression model and the exponential smoothing model involved less mathematics and statistics thus easier to be understood, and the linear regression model performed better on seasonal epidemics.",87
"A variety of statistical prediction models for time series analysis have been introduced and applied. In [6], the ARIMA model is used and the cases of COVID-19 in Italy, Spain, and France from 21 Feb to 15 April 2020 are studied. The author suggests that ARIMA models are suitable for forecasting the COVID-19 prevalence in the future. Furthermore, a Seasonal ARIMA model is adopted by to forecast cases in Italy with the data till 31st March 2020. Another popular method is the Prophet of Facebook applied the Prophet to predict both confirmed and death cases with the data from WHO from 7th April to 3rd May 2020. Those time series forecasting models have been applied during the study of dynamics of epidemic. These researches are based on data of the whole epidemic period or the period long after the outbreak. However, our project aims at forecasting the trend of epidemic at its early stage using the data of this epidemic in other regions, which can greatly contribute to the evaluation of severity and taking countermeasures when epidemics spread to a new region.",182
"Our work actually develops methods to solve zero-shot and few-shot time series prediction. Zero-shot and few-shot respectively stand for cases where there are no or a few training data of target tasks. There is relatively scarce literature on zero-shot or low-shot time series prediction. Among related works, the existing prevalent method is transfer learning, which is also adopted by us. [18,11] pre-train an RNN-based model on time series from some auxiliary tasks to learn shared features embedding. [18] adopts a Memory-endowed Ordinal Regression Deep Neural Network (MOrdReD) as the backbone model. Its experiments show its proposed framework with transfer learning outperforms the auto regression model. Nevertheless, none of those past works has implemented transfer learning on time series prediction of pandemic transmission. In addition, [15] adapted N-BEATS model [17] to few-shot time series forecasting. The model can achieve satisfying performance on zero-shot and few-shot TS prediction. However, the approach proposed is essentially a variant of N-BEATS rather than a model-agnostic framework. Thus, some mainstream time series prediction models cannot be incorporated into this approach.",174
"In this section, we first give a definition of the time series prediction task that our project focuses on. Then in Sec. 2.2, we will introduce the design of our prediction system that is made up of prediction models and results visualization. Details of the implementation are explained in Sec. 2.3. We also conduct the test of our system and evaluate the performance of our prediction model in Sec. 2.4 and Sec. 2.5 respectively.",74
"Our trained time series forecasting models are the backend for the prediction function, which is taking the user uploaded data from frontend as input and return the required prediction result. We divided the states into five groups, and each group is assigned with one model. In the project, we compare the performance of RNN and LSTM models on each group and select the better one. The RNN model can remember the previous input using its internal memory, which gives it the capability of capturing the pattern of time series. Since our goal is to predict the outbreak’s development at its early stage, the RNN model’s capability draws our attention. However, the RNN model may encounter the vanishing gradient problem which can result in difficulties in updating the parameters of model. Therefore, we also employ LSTM in our experiment, a model commonly used in processing time series that can solve the vanishing gradient problem. The structures of RNN and LSTM models we use are shown in the following figure.",168
"We conduction data visualization to give a straightforward demonstration of prediction results. The purpose of visualization is to enable viewers to swiftly have a knowledge of the situation of the spread of the virus within a period. On the one hand, we design a map where cities are highlighted by orange dots shown in Fig. 3 and Fig. 4. The more cases in a city there are, the larger the dot is to indicate the severity of pandemic transmission. Users can choose what time period to show the corresponding pandemic situation. Users can put their mouse on the dot and the data in that region will be displayed (Fig. 5). Additionally, the number of total active cases will be calculated and displayed.",122
"On the other hand, user can select the specific region (Fig. 6) to see its current time series of accumulated active cases and our prediction for the next 14 days (shown in Fig. 7). Besides, once a specific region is selected, the map will automatically focus on that region. And the number of accumulated infected cases till the time point input by user will be computed and displayed as shown in Fig. 8.",73
"The dataset used by our project is obtained from GitHub open-source database which compile the data released by the New York Times (https://github.com/nytimes/covid[1]19-data). The dataset contains the 56 state-level time series data of daily cumulative number of cases starting from January 21, 2020, when the first cases is reported in Washington. Noticing the fact that no significance outbreak was founded in American Samoa and Northern Mariana Islands, these two states will not be included in out experiment.",78
"The goal of our project is to forecast the development of an outbreak within third and fourth weeks based on the first two weeks, therefore, we are only interested in the front portion instead of the whole time series. Notice that the dataset we obtained is start from the day when first cases is reported in the whole United States, while in different states the outbreak started at different time, which will result in a series of 0 exists before the start of outbreak. Therefore, in terms of sampling, for each state, we start from the first day when the number of cases reported was increasing in its next three days so that all samples contain data of the first outbreak in the state. The first 35 days start from the start of outbreak in each states are used, and they are divided into 8 samples where each sample contains 14 days’ data for input and the next 14 days’ data for output comparison. The dataset we obtained records the cumulative number of cases, however, during the early experiment we noticed that when using daily cumulative number of cases for training, the prediction results for next 14 days may give the decrease of cumulative number of cases during some periods, which is impossible at the early stage of pandemic. Therefore, instead of using the daily cumulative number of cases directly, we use the number of daily reported new cases in our project.",242
"We also notice that the outbreak in different states may have extremely different pattern of development. As shown in the figure 9, the developing trend of COVID-19 outbreak in Alaska, California, and South Carolina are totally different, and these different patterns can’t be handled well by a single model. But we also notice that there exist some states sharing relatively similar patterns. For example, from figure 10 we can find that a relatively similar developing pattern exists in Indiana, Massachusetts, and Illinois. Therefore, we divide the states into different groups where the states in the same group have the similar development patterns. The dividing process will be introduced in the next section.",112
"As mentioned in previous section, we need to divide the states into groups such that states in the same group have similar development patterns for outbreak. Notice that the development pattern here is in fact the feature of time series that will be captured by time series forecasting models during the training process, and the model will be more likely capture the features exists in most samples, which means when we train a model on multiple regions, the model will more likely to learn the developing patterns shared by most regions, and therefore the better developing pattern of a region can be simulated by the model, the more regions does this region share the same pattern. Utilizing this fact, we first train our LSTM model with data from different states, then we evaluate how the model can simulated these states and remove the states that the model can’t simulate well. Assuming the pattern 1 represents the pattern that is shared by some states which we are going to put into a same group, those states that can’t be simulated well definitely contain different patterns other than pattern 1, but among the states that can be simulated well, there might exist states that also sharing some features with both pattern 1 and other patterns, which means these states should not be put into the groups. Therefore, we should train the model on the states left again and remove those states can’t be simulated well, and the process is repeated until all states left can be simulated well by the same LSTM model, which means all these states are sharing some similar developing patterns of outbreak, and then a group can be form using these states. To evaluate how well the model can simulate the developing patterns, we use the Root Relative Squared Error (RRSE) between the prediction result and the ground truth. The formulation of RRSE is shown below.",318
"We have formed 4 groups of states, and there are 22 states left which can’t be divided into any groups. The following tables show the information of each group. Notice that at this stage we are only splitting the states into groups instead of testing the models, the RRSE here is obtained by evaluating the prediction result on training dataset which is all states in each group.",67
"We apply LSTM model and RNN models for our experiment. For the four groups sharing the similar patterns, we apply the models trained with data from the states in the group. And for the rest of the states, considering the fact that these groups can’t be divided into any groups is because they don’t share a similar developing pattern, therefore for these states we train the model with data from all 54 states then applied to these states.",78
"Our web UI is built based on an open-source library Streamlit. Streamlit enables programmers to build an interactive web with python alone. Conventionally, programming for web uses html and JavaScript. But in that way, codes are usually very long and hard to construct. Therefore, we leverage open-source library like Streamlit that wraps up foundational web functions and offer convenient application programming interfaces (APIs).",63
"There are mainly two main tasks to handle, that is a real-time map reflecting the pandemic situation and collaboration with backend prediction model and data. For the first task, we utilize the Google geocoding API to obtain the latitude and longitude of a certain place. Instead of requesting the service of Google Maps platform at running time, we obtain all geographical data needed in advance and store them into a local file. Then our backend can directly read data locally. In that way, a great amount of processing time will be saved at running time and our web UI will be more responsive. Then given the latitudes and longitudes of cities, csv files recording pandemic situation of each city will be read to extract daily infected cases. Then we can have a data frame storing the name of a city, its geographical location and corresponding time series of infected cases. Based on the processed data, we take advantage of a library called pydeck to generate a map which marks each city with orange dots. We customize the map by programming the size of dots to change along with the number of infected cases in that city. Then we can use pre-defined function of Streamlit to display the map on the webpage.",211
"For the second task, after users input the time period and select region of interest, corresponding data will be fetched and calculated. For instance, if users choose ‘New York’, the geographical position of New York and corresponding data of active cases will be extracted from the csv files. Based on those data, the map will then be programmed to zoom in and focus on the location of New York. On the other hand, under the framework of Tensorflow, our model will load trained weight file. The past 14-day time series of New York will be input into the model to get prediction result. Graphs of predicted time series will then be drawn with plotly, a graphing library.",117
"For the rest of 22 states, due to the long execution time, instead of using cross validation, we select 5 states from these 22 states for testing. The five testing states are Alaska, Hawaii, Mississippi, Ohio, and South Carolina. As mentioned in section 2.3.3, for these 22 states we are applying the model trained by data from all 54 states for our application. Therefore, during the testing process, we use the rest 49 states other than the 5 testing states for training, and we evaluate the performance of the trained model on the 5 testing states.",96
The following tables shows the performance of LSTM and RNN model on the four groups and the rest 22 states. The visualization result of comparison between prediction result and ground truth in 8 states is shown in the figure 11.,40
"Based on the prediction result, on the four groups of states, the LSTM model provides a better performance in terms of RRSE. And only in Group 3 the performance of LSTM model in terms of RMSE is worse than the RNN model. For the rest of 22 states, the RNN model can obtain a better performance both on RMSE and RRSE, therefore, we select the LSTM model for the four groups and the RNN model for the rest of 22 states in our application.",84
"To test the effectiveness of models, we need to conduct multiple experiments and take the average of results to compare it with the performance of the baseline or existing models. Significance test may be needed when the difference of performance of two models is small.",45
"We first test our input section with mainly three kinds of input, that is lower-bound inputs, upper-bound inputs, and inputs within the bounds.",23
Lower-bound cases: We test with negative number first and our web will identify this error case and return message to ask advice users to modify their inputs. Figure 13 shows an instance. We test our web with 20 randomly generated negative numbers ranging from –1 to –10000. And there are no error cases triggered.,54
"When doing prediction for a certain region, the input number is required to be larger than 14. Because our model is trained to predict the future time series with past 14-day data points. In that case, we test our web with input from 0 to 13. And all cases are handled by returning messages to advice users to update their inputs (see Fig. 14). However, if no regions are selected to conduct prediction, our web is programmed to show the content normally.",82
"Upper-bound cases: If the input number for period is larger than the length of available data, the backend will access to some non-existing data, thus triggering errors. And our cases should handle this case. We test our web with ten numbers that are larger than 400. Our web can handle the bad inputs by returning messages to let users make inputs smaller.",62
"Inputs within the bounds: The input number should be an integer. Our codes round non-integer inputs to the nearest positive integers. For cases that non-integer inputs cannot be rounded successfully, and inputs are not even numerical, messages will be printed to tell users to input rational integers. We test our web with five symbols (e.g., ‘/’, ‘>’, ‘).",58
"When a specific region is selected and the button ‘show’ is clicked, the main should show the time series of that selected region. The map will be adjusted to zoom in and focus on the region chosen. By default, ‘All’ is shown in the selector and the map zooms out shown in Fig. 18. In that case where no region is specified, we test the web by directing clicking button ‘show’. Our web does not report errors and still displays the default page. We then test our web by selecting each available region. And our web UI can show contents needed normally. The map can automatically adjust itself to focus on the corresponding selected region.",115
We also test the web by switching regions. The region is switched from a specified one to ‘All’. Or the region is switched from one specified place to another. Our web functions correctly in all cases.,36
We repeated the tests above under multiple cases where different time period is input by users. There were no errors that had happened.,23
